{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "-  The dataset I have wrangled is the tweet archive of Twitter account called @dog_rates_(https://twitter.com/dog_rates), also known as WeRateDogs (https://twitter.com/dog_rates). WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog.\n",
    "\n",
    "\n",
    "-  In this report I will briefly describe my Wrangling efforts done on the data associated with WeRateDogs Twitter account\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gathering Information for this project\n",
    "\n",
    "This undertaking included assembling of information from three distinct sources as recorded underneath. For every one of the information source an alternate strategy for information gathering was utilized in particular:-\n",
    "\n",
    "Bringing in information by means of csv\n",
    "Utilizing solicitations to download information off web\n",
    "\n",
    "\n",
    "-  Three information sources\n",
    "\n",
    "\n",
    "- Twitter Enhanced Archive\n",
    "The WeRateDogs Twitter archive given by Udacity. This contains essential tweet information for all 5000+ of their tweets, yet not everything.I physically downloaded this document physically by tapping the accompanying connection: twitter_archive_enhanced.csv\n",
    "\n",
    "\n",
    "\n",
    "-  Image Predictions File\n",
    "The tweet Image foreasts, thus what type of dog(or other item, animal, and so on) is available in each tweet according to a neural network . This document (image_predictions.tsv) is facilitated on Udacity's servers and ought to be downloaded automatically utilizing the Solicitations library and the accompanying URL: image_predictions.tsv\n",
    "\n",
    "\n",
    "\n",
    "-  Data via the Twitter API\n",
    " Using  resources by Udacity as zip file  to acquire my tweet's JSON data \n",
    "Each tweet's retweet count and most loved (\"like\") count at least, and any extra information you view as fascinating. Involving the tweet IDs in the WeRateDogs Twitter document, question the Twitter Programming interface for each tweet's JSON information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Assessing data\n",
    "\n",
    "- Assessing Data I assessed the gathered data both visually and programmatically for quality and tidiness issues.\n",
    "\n",
    "\n",
    "-  The Programmatic Assessment required using a range of Pandas functions and methods such as\n",
    "-     info()\n",
    "-     describe()\n",
    "-     head() \n",
    "-     sample() \n",
    "-     value_ counts() and\n",
    "-     .unique().\n",
    "\n",
    "\n",
    "-  Here are the issues I've detected:\n",
    "\n",
    "The data we got was messy compared to the standard format or to the way we want it. After gathering the required data, I came up with the following issues with it:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Issues;\n",
    "\n",
    "\n",
    "-  Twitter_archive\n",
    "\n",
    "Missing Values :\n",
    "\n",
    "- in_reply_to_status_id, in_reply_to_user_id : 78 instead of 2356\n",
    "retweeted_status_id,retweeted_status_user_id,retweeted_status_timestamp 181 instead of 2356\n",
    "expanded_urls : 2297 instead of 2356\n",
    "- We are interested in the tweet ONLY not the retweet\n",
    "- We are interested in the tweet ONLY not the reply to the original tweet\n",
    "\n",
    "- tweet_id is saved as int datatype instead of/ \"better to be\" string (object)\n",
    "\n",
    "- timestamp , retweeted_status_timestamp are saved as object datatype (str) instead of date/timestamp\n",
    "source column is writen in html containg <a> tags\n",
    "column name :\n",
    "\n",
    "- some values are not titled untitled_unlowers ('BeBe','DonDon','CeCe',, 'JD', 'DayZ')\n",
    "- some are inacuarte values : lowers ['such', 'a', 'quite', 'not', 'one', 'incredibly', 'mad','an', 'very', 'just', 'my', 'his', 'actually', 'getting','this', 'unacceptable', 'all', 'old', 'infuriating', 'the','by', 'officially', 'life', 'light', 'space']\n",
    "rating_numerator & rating_denominator:\n",
    "\n",
    "datatype for rating_numerator should be float instead of int\n",
    "fix:\n",
    "- @45 13.5/10 instead of 5/10\n",
    "- @ 313 13/10 instead of 960/0\n",
    "- @ 2335 : 9/10 instead of 1/2\n",
    "- @ 1068 : 14/10 instead of 9/11\n",
    "- @1165: 13/10 instead of 4/20\n",
    "- @ 1202 : 11/10 instead of 50/50\n",
    "- @ 1662 10/10 instead of 7/11\n",
    "- @ 695 : 9.75/10 instead of 75/10\n",
    "- @763 : 11.27/10 instead of 27/10\n",
    "- @- 1712 :11.26/10 instead of 26/10\n",
    "\n",
    "- drop:\n",
    "- @ 516 no rating\n",
    "- @342 inaccurate (account start date)\n",
    "\n",
    "- invistigate(outliers):\n",
    "- @ 315 https://t.co/YbEJPkg4Ag 0/10\n",
    "- @979 1776/10\n",
    "- @ 1634 : https://t.co/kRK51Y5ac3 143/130\n",
    "- @2074 :420/10\n",
    "- @1274 names\n",
    "columns doggo,floofer,pupper, puppo has None values instead of Null.\n",
    "We are interested in dogs , text column reveals the truth about that some tweets are not related to dogs\n",
    "expanded_urls is too bulky we are interested in tweet link only.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-  Tidiness issues:\n",
    "\n",
    "\n",
    "-  I twitter archive\n",
    "- text column has two variables text and short urls, create short _urls column, drop\n",
    "expanded uns\n",
    "-   The values of four columns (doggo, floofer,pupper,puppo) in twitter archive dataset\n",
    "should be in one column dog stage with a category datatype.\n",
    "- rating_ numerator and rating_denominator columns in twitter archive dataset should\n",
    "Torm one column dog_rating normalized out of 10.\n",
    "- make new columns for day_name and month from the timstamp column\n",
    "image pred\n",
    "- Columns p1, p1_dog, p1 conf, p2, p2 dog. p2 conf, p3, p3 dog, p3_ conf could becondenced to two columns dog breed and confidence\n",
    "\n",
    "- All datasets\n",
    "\n",
    "-  tweet id is present in two datasets and after renaming it will appear in all datasets\n",
    "- tweet_json and image pred datasets should be part of our main dataset\n",
    "twitter archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cleaning Data\n",
    "\n",
    "My main approach in the cleaning process is First things first So, I started with the;\n",
    "\n",
    "-  Missing Data\n",
    "\n",
    "-  Tidiness\n",
    "\n",
    "-  Other Quality Issues,\n",
    "\n",
    "-  It is important to state here that I focus more on Tideness issues and do what ever quality cleaning leads to that point.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- I utilized my insight into python and looking through over the web for example google, stackoverflow, stackabuse and so on for references and conceivable guidance to determine the previously mentioned issues apparently. There was part experimentation for troublesome situations where normal articulations must be involved and yet a few things for example dropping the not so helpful sections was straight forward.\n",
    "\n",
    "\n",
    "- In general, I gained some significant experience about how to utilize python actually and proficiently to clean information and store it.\n",
    "\n",
    "\n",
    "- At last, when the information was prepared I broke down it involving perceptions as report in act_report.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
